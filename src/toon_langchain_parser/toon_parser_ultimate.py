# -*- coding: utf-8 -*-

from __future__ import annotations

import csv
import io
import re
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple, Type, Union

try:
    from pydantic import BaseModel
except Exception as e:  # pragma: no cover
    raise ImportError("pydantic(v2) is required. Install: pip install pydantic>=2") from e


# ============================================================
# Errors
# ============================================================
class ToonParserError(ValueError):
    pass


class ToonDecodeError(ToonParserError):
    pass


class PolicyViolationError(ToonParserError):
    pass


class SchemaViolationError(ToonParserError):
    pass


class ModelComplexityError(ToonParserError):
    """minimal ëª¨ë“œì—ì„œ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë³µì¡í•œ ìŠ¤í‚¤ë§ˆì¼ ë•Œ ë°œìƒí•˜ëŠ” ì—ëŸ¬."""
    pass


# ============================================================
# Config
# ============================================================
@dataclass(frozen=True)
class ParserConfig:
    indent_step: int = 2
    complexity_threshold: int = 3  # item ?? ??? ? ? ??? complex? ??
    protect_string_ids: bool = True
    strict_schema: bool = True
    strict_count: bool = False
    allow_tabular_for_flat_objects: bool = True
    
    # Format instructions ìŠ¤íƒ€ì¼ ì„ íƒ
    instructions_mode: str = "adaptive"  # "adaptive" | "minimal" | "json"
    # - adaptive: ìƒì„¸í•œ ì„¤ëª… (1762 chars, ì†ìµë¶„ê¸° 19,363 chars)
    # - minimal: Few-shot ìŠ¤íƒ€ì¼ (102 chars, ì†ìµë¶„ê¸° 1,121 chars) â­ ê¶Œì¥
    # - json: JSON í¬ë§· ì‚¬ìš© (TOON ë¹„í™œì„±í™”)
    
    # minimal ëª¨ë“œ ë™ì‘ ì„¤ì •
    auto_fallback_to_json: bool = True  # minimal ëª¨ë“œì—ì„œ ë³µì¡í•œ ìŠ¤í‚¤ë§ˆ ê°ì§€ ì‹œ ìë™ìœ¼ë¡œ jsonìœ¼ë¡œ í´ë°±
    strict_minimal_validation: bool = False  # Trueì‹œ ë³µì¡í•œ ìŠ¤í‚¤ë§ˆì—ì„œ ì—ëŸ¬ ë°œìƒ (í´ë°± ì•ˆ í•¨)


# ============================================================
# Model Complexity Validator
# ============================================================
@dataclass(frozen=True)
class ComplexityLimits:
    """minimal ëª¨ë“œì—ì„œ ì§€ì› ê°€ëŠ¥í•œ ìŠ¤í‚¤ë§ˆì˜ ë³µì¡ë„ ì œí•œ.
    
    í•µì‹¬ ì œì•½: depth(ì¤‘ì²© ê¹Šì´)ë§Œ ì œí•œ
    - Level 1 (flat): í•„ë“œ ê°œìˆ˜, íƒ€ì… ë³µì¡ë„ ë¬´ê´€í•˜ê²Œ ëª¨ë‘ ì§€ì›
    - Level 2 (1ë‹¨ê³„ ì¤‘ì²©): ëŒ€ë¶€ë¶„ ì§€ì›
    - Level 3+ (2ë‹¨ê³„ ì´ìƒ ì¤‘ì²©): LLMì´ TOON í˜•ì‹ì„ ì œëŒ€ë¡œ ì¶œë ¥ ëª»í•  ê°€ëŠ¥ì„± ë†’ìŒ
    """
    max_nesting_depth: int = 2  # ìµœëŒ€ ì¤‘ì²© ê¹Šì´ (ê°ì²´ ì•ˆì˜ ê°ì²´) - ğŸ¯ í•µì‹¬ ì œì•½
    
    # ì•„ë˜ ì œì•½ë“¤ì€ ì‚¬ì‹¤ìƒ ë¬´ì œí•œ (ë§¤ìš° í° ê°’ìœ¼ë¡œ ì„¤ì •)
    max_array_nesting: int = 999  # ë°°ì—´ ì¤‘ì²©ì€ ì œí•œ ì—†ìŒ
    max_union_types: int = 999  # Union íƒ€ì… í•„ë“œ ê°œìˆ˜ ì œí•œ ì—†ìŒ
    max_object_fields: int = 999  # flat ê°ì²´ í•„ë“œ ê°œìˆ˜ ì œí•œ ì—†ìŒ
    max_array_item_fields: int = 999  # ë°°ì—´ ì•„ì´í…œ í•„ë“œ ê°œìˆ˜ ì œí•œ ì—†ìŒ
    allow_nested_unions: bool = True  # ì¤‘ì²© Union í—ˆìš©
    allow_recursive_refs: bool = False  # ì¬ê·€ $refë§Œ ë¶ˆí—ˆ (ë¬´í•œ ë£¨í”„ ë°©ì§€)


class ComplexityMetrics:
    """ìŠ¤í‚¤ë§ˆì˜ ë³µì¡ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ë©”íŠ¸ë¦­."""
    
    def __init__(self):
        self.max_nesting_depth = 0
        self.max_array_nesting = 0
        self.union_type_count = 0
        self.max_object_fields = 0
        self.max_array_item_fields = 0
        self.has_nested_unions = False
        self.has_recursive_refs = False
        self.violation_reasons: List[str] = []
    
    def add_violation(self, reason: str):
        """ì œì•½ ìœ„ë°˜ ì‚¬í•­ì„ ê¸°ë¡."""
        self.violation_reasons.append(reason)
    
    def is_within_limits(self, limits: ComplexityLimits) -> bool:
        """ì£¼ì–´ì§„ ì œì•½ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸."""
        self.violation_reasons.clear()
        
        if self.max_nesting_depth > limits.max_nesting_depth:
            self.add_violation(
                f"ì¤‘ì²© ê¹Šì´ ì´ˆê³¼: {self.max_nesting_depth} > {limits.max_nesting_depth} "
                f"(ê°ì²´ ì•ˆì— ê°ì²´ê°€ {self.max_nesting_depth}ë‹¨ê³„ ì¤‘ì²©ë¨)"
            )
        
        if self.max_array_nesting > limits.max_array_nesting:
            self.add_violation(
                f"ë°°ì—´ ì¤‘ì²© ê¹Šì´ ì´ˆê³¼: {self.max_array_nesting} > {limits.max_array_nesting} "
                f"(ë°°ì—´ ì•ˆì— ë°°ì—´ì´ {self.max_array_nesting}ë‹¨ê³„ ì¤‘ì²©ë¨)"
            )
        
        if self.union_type_count > limits.max_union_types:
            self.add_violation(
                f"Union íƒ€ì… ê°œìˆ˜ ì´ˆê³¼: {self.union_type_count} > {limits.max_union_types} "
                f"(Union íƒ€ì… í•„ë“œê°€ ë„ˆë¬´ ë§ìŒ)"
            )
        
        if self.max_object_fields > limits.max_object_fields:
            self.add_violation(
                f"ê°ì²´ í•„ë“œ ê°œìˆ˜ ì´ˆê³¼: {self.max_object_fields} > {limits.max_object_fields} "
                f"(ë‹¨ì¼ ê°ì²´ì— í•„ë“œê°€ ë„ˆë¬´ ë§ìŒ)"
            )
        
        if self.max_array_item_fields > limits.max_array_item_fields:
            self.add_violation(
                f"ë°°ì—´ ì•„ì´í…œ í•„ë“œ ê°œìˆ˜ ì´ˆê³¼: {self.max_array_item_fields} > {limits.max_array_item_fields} "
                f"(ë°°ì—´ì˜ ê° ì•„ì´í…œ ê°ì²´ì— í•„ë“œê°€ ë„ˆë¬´ ë§ìŒ)"
            )
        
        if self.has_nested_unions and not limits.allow_nested_unions:
            self.add_violation("ì¤‘ì²©ëœ Union íƒ€ì… ë°œê²¬ (ì˜ˆ: Union[List[Union[str, int]], Dict])")
        
        if self.has_recursive_refs and not limits.allow_recursive_refs:
            self.add_violation("ì¬ê·€ì  $ref ë°œê²¬ (ì˜ˆ: Node â†’ children: List[Node])")
        
        return len(self.violation_reasons) == 0
    
    def get_violation_summary(self) -> str:
        """ì œì•½ ìœ„ë°˜ ì‚¬í•­ì„ ìš”ì•½í•œ ë¬¸ìì—´ ë°˜í™˜."""
        if not self.violation_reasons:
            return "ì œì•½ ìœ„ë°˜ ì—†ìŒ"
        
        return "\n".join(f"  - {reason}" for reason in self.violation_reasons)


class ModelComplexityAnalyzer:
    """BaseModelì˜ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤."""
    
    def __init__(self, model: Type[BaseModel]):
        self.model = model
        self.schema = model.model_json_schema()
        self._defs: Dict[str, Any] = {}
        
        if isinstance(self.schema, dict):
            if isinstance(self.schema.get("$defs"), dict):
                self._defs.update(self.schema["$defs"])
            if isinstance(self.schema.get("definitions"), dict):
                self._defs.update(self.schema["definitions"])
        
        self.metrics = ComplexityMetrics()
        self._visited_refs: set = set()
    
    def analyze(self) -> ComplexityMetrics:
        """ìŠ¤í‚¤ë§ˆì˜ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ê³  ë©”íŠ¸ë¦­ì„ ë°˜í™˜."""
        self._analyze_schema(self.schema, depth=0, array_depth=0, path="$")
        return self.metrics
    
    def _resolve_ref(self, ref: str) -> Dict[str, Any]:
        """$refë¥¼ í•´ì„í•˜ì—¬ ì‹¤ì œ ìŠ¤í‚¤ë§ˆ ë°˜í™˜."""
        if not ref.startswith("#/"):
            return {}
        parts = ref.lstrip("#/").split("/")
        if len(parts) == 2 and parts[0] in ("$defs", "definitions"):
            name = parts[1]
            return self._defs.get(name, {})
        return {}
    
    def _analyze_schema(
        self, 
        schema: Dict[str, Any], 
        depth: int, 
        array_depth: int, 
        path: str,
        in_union: bool = False
    ):
        """ì¬ê·€ì ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆë¥¼ ë¶„ì„."""
        if not isinstance(schema, dict):
            return
        
        # $ref ì²˜ë¦¬
        if "$ref" in schema:
            ref = schema["$ref"]
            if ref in self._visited_refs:
                self.metrics.has_recursive_refs = True
                return
            self._visited_refs.add(ref)
            resolved = self._resolve_ref(ref)
            self._analyze_schema(resolved, depth, array_depth, f"{path}.$ref", in_union)
            self._visited_refs.discard(ref)
            return
        
        # Union íƒ€ì… ì²˜ë¦¬
        if "anyOf" in schema or "oneOf" in schema:
            self.metrics.union_type_count += 1
            
            if in_union:
                self.metrics.has_nested_unions = True
            
            union_schemas = schema.get("anyOf", schema.get("oneOf", []))
            for idx, sub_schema in enumerate(union_schemas):
                if isinstance(sub_schema, dict):
                    self._analyze_schema(
                        sub_schema, 
                        depth, 
                        array_depth, 
                        f"{path}.union[{idx}]",
                        in_union=True
                    )
            return
        
        schema_type = schema.get("type")
        
        # ê°ì²´ íƒ€ì…
        if schema_type == "object" or "properties" in schema:
            props = schema.get("properties", {}) or {}
            field_count = len(props)
            
            # ê°ì²´ í•„ë“œ ê°œìˆ˜ ì—…ë°ì´íŠ¸
            if array_depth > 0:
                # ë°°ì—´ ì•„ì´í…œì¸ ê²½ìš°
                self.metrics.max_array_item_fields = max(
                    self.metrics.max_array_item_fields, 
                    field_count
                )
            else:
                # ì¼ë°˜ ê°ì²´ì¸ ê²½ìš°
                self.metrics.max_object_fields = max(
                    self.metrics.max_object_fields, 
                    field_count
                )
            
            # ì¤‘ì²© ê¹Šì´ ì—…ë°ì´íŠ¸
            self.metrics.max_nesting_depth = max(self.metrics.max_nesting_depth, depth)
            
            # ê° í•„ë“œì— ëŒ€í•´ ì¬ê·€ ë¶„ì„
            for field_name, field_schema in props.items():
                self._analyze_schema(
                    field_schema, 
                    depth + 1, 
                    array_depth, 
                    f"{path}.{field_name}",
                    in_union
                )
        
        # ë°°ì—´ íƒ€ì…
        elif schema_type == "array":
            items_schema = schema.get("items", {}) or {}
            
            # ë°°ì—´ ì¤‘ì²© ê¹Šì´ ì—…ë°ì´íŠ¸
            new_array_depth = array_depth + 1
            self.metrics.max_array_nesting = max(
                self.metrics.max_array_nesting, 
                new_array_depth
            )
            
            # ë°°ì—´ ì•„ì´í…œì— ëŒ€í•´ ì¬ê·€ ë¶„ì„
            self._analyze_schema(
                items_schema, 
                depth, 
                new_array_depth, 
                f"{path}[]",
                in_union
            )
    
    @staticmethod
    def validate_for_minimal_mode(
        model: Type[BaseModel], 
        limits: Optional[ComplexityLimits] = None
    ) -> Tuple[bool, ComplexityMetrics]:
        """minimal ëª¨ë“œì— ì í•©í•œ ëª¨ë¸ì¸ì§€ ê²€ì¦.
        
        Args:
            model: ê²€ì¦í•  Pydantic BaseModel
            limits: ë³µì¡ë„ ì œí•œ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        
        Returns:
            (is_valid, metrics) íŠœí”Œ
        """
        if limits is None:
            limits = ComplexityLimits()
        
        analyzer = ModelComplexityAnalyzer(model)
        metrics = analyzer.analyze()
        is_valid = metrics.is_within_limits(limits)
        
        return is_valid, metrics


# ============================================================
# Adaptive Prompt Builder
# ============================================================
class ToonIntelligence:
    @staticmethod
    def _props(schema: Dict[str, Any]) -> Dict[str, Any]:
        return schema.get("properties", {}) or {}

    @staticmethod
    def _items(schema: Dict[str, Any]) -> Dict[str, Any]:
        return schema.get("items", {}) or {}

    @staticmethod
    def _is_scalar_type(t: str) -> bool:
        return t in ("string", "integer", "number", "boolean")

    @staticmethod
    def _dummy_scalar(t: str) -> str:
        if t == "string":
            return "text"
        if t == "integer":
            return "1"
        if t == "number":
            return "0.1"
        if t == "boolean":
            return "true"
        return "text"

    @staticmethod
    def is_complex_array(field_schema: Dict[str, Any], threshold: int) -> bool:
        if field_schema.get("type") != "array":
            return False
        items = ToonIntelligence._items(field_schema)

        # $ref / anyOf ?? ????? complex? ??
        if "$ref" in items or "anyOf" in items or "oneOf" in items or "allOf" in items:
            return True

        item_type = items.get("type")
        if item_type not in (None, "object"):
            return True

        props = items.get("properties", {}) or {}

        # ?? ??(??/??) ?? -> complex
        for v in props.values():
            t = v.get("type")
            if t in ("object", "array") or "$ref" in v or "anyOf" in v or "oneOf" in v or "allOf" in v:
                return True

        # ?? ?? ??? complex? ??
        return len(props) > threshold

    @staticmethod
    def is_flat_object_array(field_schema: Dict[str, Any]) -> bool:
        if field_schema.get("type") != "array":
            return False
        items = ToonIntelligence._items(field_schema)
        if items.get("type") not in (None, "object"):
            return False
        props = items.get("properties", {}) or {}
        if not props:
            return False
        return all(ToonIntelligence._is_scalar_type((v.get("type") or "string")) for v in props.values())

    @staticmethod
    def _detect_union_types(props: Dict[str, Any]) -> List[str]:
        """Union íƒ€ì…ì„ ê°€ì§„ í•„ë“œ ê°ì§€."""
        union_fields = []
        for fname, fsch in props.items():
            # anyOf, oneOf ì²´í¬
            if "anyOf" in fsch or "oneOf" in fsch:
                union_fields.append(fname)
            # Python 3.10+ union syntax (str | int | None)
            elif isinstance(fsch.get("type"), list):
                union_fields.append(fname)
        return union_fields
    
    @staticmethod
    def _detect_string_fields(props: Dict[str, Any]) -> List[str]:
        """String íƒ€ì… í•„ë“œ ê°ì§€."""
        return [fname for fname, fsch in props.items() if fsch.get("type") == "string"]
    
    @staticmethod
    def _detect_special_char_fields(props: Dict[str, Any]) -> List[str]:
        """íŠ¹ìˆ˜ ë¬¸ìê°€ í¬í•¨ë  ê°€ëŠ¥ì„±ì´ ìˆëŠ” í•„ë“œ ê°ì§€ (descriptionì— íŠ¹ìˆ˜ë¬¸ì ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨)."""
        keywords = ["url", "email", "code", "json", "colon", ":", "-", "dash", "special"]
        special_fields = []
        for fname, fsch in props.items():
            desc = (fsch.get("description", "") or "").lower()
            if any(kw in desc or kw in fname.lower() for kw in keywords):
                special_fields.append(fname)
        return special_fields

    @staticmethod
    def build_adaptive_prompt(model: Type[BaseModel], cfg: ParserConfig = ParserConfig()) -> str:
        schema = model.model_json_schema()
        props = schema.get("properties", {}) or {}
        required_fields = set(schema.get("required", []))
        
        # ìŠ¤í‚¤ë§ˆ ë¶„ì„
        union_fields = ToonIntelligence._detect_union_types(props)
        string_fields = ToonIntelligence._detect_string_fields(props)
        special_char_fields = ToonIntelligence._detect_special_char_fields(props)

        out: List[str] = []
        out.append("### TOON FORMAT GUIDE (MUST FOLLOW EXACTLY)")
        out.append("")
        out.append("TOON is a simple, indentation-based format similar to YAML but simpler.")
        out.append("")
        out.append("#### CORE RULES:")
        out.append("1. Use 2 spaces for each indentation level (NEVER tabs)")
        out.append("2. Every line MUST have a colon (:) - format is always 'key: value' or 'key:' for nested")
        out.append("3. Output ONLY TOON format - NEVER mix with JSON, YAML, or plain text")
        out.append("4. ALL REQUIRED FIELDS MUST BE INCLUDED - validation will fail if any are missing")
        out.append("")
        
        # List required fields prominently
        if required_fields:
            out.append("#### REQUIRED FIELDS (MUST INCLUDE ALL):")
            for fname in sorted(required_fields):
                fsch = props.get(fname, {})
                ftype = fsch.get("type", "any")
                fdesc = fsch.get("description", "")
                out.append(f"âœ“ {fname}: {ftype}" + (f" - {fdesc}" if fdesc else ""))
            out.append("")
        
        out.append("")
        out.append("#### BASIC SYNTAX:")
        out.append("```")
        out.append("# Simple values (inline)")
        out.append("name: John")
        out.append("age: 30")
        out.append("active: true")
        out.append("score: 95.5")
        out.append("unknown: null")
        out.append("")
        out.append("# Nested object (colon, then indent 2 spaces)")
        out.append("address:")
        out.append("  street: Main St")
        out.append("  city: NYC")
        out.append("")
        out.append("# Empty object/array")
        out.append("empty_object: {}")
        out.append("empty_array: []")
        out.append("```")
        out.append("")
        out.append("#### NUMBER FORMATTING:")
        out.append("- NEVER use thousand separators: 25000 (NOT 25,000)")
        out.append("- Integers: 42")
        out.append("- Decimals: 3.14")
        out.append("")

        # ======= ë™ì  íƒ€ì…ë³„ ê°€ì´ë“œ ì¶”ê°€ =======
        
        # String í•„ë“œ ê²½ê³ 
        if string_fields:
            out.append("#### âš ï¸ CRITICAL: STRING FIELD RULES")
            out.append("")
            out.append("**String íƒ€ì… í•„ë“œëŠ” ë°˜ë“œì‹œ ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶œë ¥:**")
            for fname in string_fields[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                out.append(f"- {fname}: MUST be single string value (NOT list/array)")
            out.append("")
            out.append("âŒ WRONG (list format):")
            out.append(f"{string_fields[0]}:")
            out.append('  - "item 1"')
            out.append('  - "item 2"')
            out.append("")
            out.append("âœ… CORRECT (single string):")
            out.append(f'{string_fields[0]}: "item 1, item 2"')
            out.append("")
        
        # Union íƒ€ì… ê°€ì´ë“œ
        if union_fields:
            out.append("#### âš ï¸ UNION TYPE FIELDS (Multiple Types Allowed)")
            out.append("")
            out.append("**ë‹¤ìŒ í•„ë“œë“¤ì€ ì—¬ëŸ¬ íƒ€ì… ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ:**")
            for fname in union_fields[:5]:
                fsch = props.get(fname, {})
                any_of = fsch.get("anyOf", fsch.get("oneOf", []))
                types = [s.get("type", "any") for s in any_of if isinstance(s, dict)]
                if types:
                    out.append(f"- {fname}: Choose one â†’ {' | '.join(types)}")
            out.append("")
            out.append("**íƒ€ì… ì„ íƒ ê·œì¹™:**")
            out.append("1. ë¬¸ì„œì—ì„œ ìˆ«ìë©´ â†’ ìˆ«ìë¡œ ì¶œë ¥ (e.g., count: 30)")
            out.append("2. ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë©´ â†’ ë¬¸ìì—´ë¡œ ì¶œë ¥ (e.g., value: \"text\")")
            out.append("3. ë°°ì—´ì´ë©´ â†’ ì½¤ë§ˆ í˜•ì‹ ë˜ëŠ” ëŒ€ì‹œ í˜•ì‹ (NOT JSON string like '[\"a\",\"b\"]')")
            out.append("4. ê°ì²´ë©´ â†’ ì¤‘ì²© í˜•ì‹ (NOT JSON string like '{\"key\":\"value\"}')")
            out.append("")
            out.append("âŒ WRONG (JSON string):")
            out.append('metadata: ["tag1", "tag2", "tag3"]')
            out.append("")
            out.append("âœ… CORRECT (actual list):")
            out.append("metadata[3]: tag1,tag2,tag3")
            out.append("")
        
        # íŠ¹ìˆ˜ ë¬¸ì í•„ë“œ ê°€ì´ë“œ
        if special_char_fields:
            out.append("#### âš ï¸ SPECIAL CHARACTER HANDLING")
            out.append("")
            out.append("**ë‹¤ìŒ í•„ë“œë“¤ì€ íŠ¹ìˆ˜ ë¬¸ìë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:**")
            for fname in special_char_fields[:5]:
                out.append(f"- {fname}: Use quotes if contains :, -, or special chars")
            out.append("")
            out.append("**ë”°ì˜´í‘œ ì‚¬ìš© ê·œì¹™:**")
            out.append('âœ… description: "This has: special chars"')
            out.append('âœ… note: "- This starts with dash"')
            out.append('âœ… code: "def func(x: int) -> str: return x"')
            out.append("âœ… url: https://example.com (quotes optional for URLs)")
            out.append("")

        out.append("#### ARRAY FORMATS:")
        out.append("")
        out.append("**Option 1: Dash List (MOST COMMON - USE THIS FOR OBJECTS)**")
        out.append("```")
        out.append("items:")
        out.append("  - name: Item1")
        out.append("    value: 100")
        out.append("  - name: Item2")
        out.append("    value: 200")
        out.append("```")
        out.append("CRITICAL: Each item starts with '- ' (dash + space) at the same indent level")
        out.append("CRITICAL: Additional fields continue with 2 more spaces (no dash)")
        out.append("")
        out.append("**Option 2: Inline Scalar List (ONLY for simple values)**")
        out.append("```")
        out.append("tags[3]: red,green,blue")
        out.append("numbers[2]: 10,20")
        out.append("```")
        out.append("Use ONLY when items are simple strings/numbers, NOT objects")
        out.append("")
        out.append("**Option 3: Tabular (ONLY for flat objects with few fields)**")
        out.append("```")
        out.append("items[2,]{name,value}:")
        out.append("  Item1,100")
        out.append("  Item2,200")
        out.append("```")
        out.append("NEVER add row numbers like: 0,Item1,100 or 1,Item2,200")
        out.append("")
        out.append("#### SCHEMA-SPECIFIC ARRAY FORMATS:")
        
        for fname, fsch in props.items():
            if fsch.get("type") != "array":
                continue

            items = fsch.get("items", {}) or {}
            # scalar array
            if items.get("type") in ("string", "integer", "number", "boolean"):
                t = items.get("type")
                out.append(f"- {fname}: Use inline format -> {fname}[N]: value1,value2,value3")
                continue

            complex_ = ToonIntelligence.is_complex_array(fsch, cfg.complexity_threshold)
            flat_ = ToonIntelligence.is_flat_object_array(fsch)
            item_props = (items.get("properties", {}) or {})

            if complex_:
                out.append(f"- {fname}: MUST use dash list (complex objects)")
                keys = list(item_props.keys())[:3] or ["field1", "field2"]
                out.append(f"  {fname}:")
                out.append(f"    - {keys[0]}: example")
                if len(keys) > 1:
                    out.append(f"      {keys[1]}: example")
                if len(keys) > 2:
                    out.append(f"      {keys[2]}: example")
            else:
                out.append(f"- {fname}: Use dash list (recommended)")
                keys = list(item_props.keys())[:2] or ["field1", "field2"]
                out.append(f"  {fname}:")
                out.append(f"    - {keys[0]}: example")
                if len(keys) > 1:
                    out.append(f"      {keys[1]}: example")

        out.append("")
        out.append("#### COMMON MISTAKES TO AVOID:")
        out.append("")
        out.append("âŒ WRONG: Standalone word without colon")
        out.append("TOON")
        out.append("items")
        out.append("")
        out.append("âœ… CORRECT: Always use key: value")
        out.append("format: TOON")
        out.append("items: []")
        out.append("")
        out.append("âŒ WRONG: Missing dash space in lists")
        out.append("items:")
        out.append("  -name: value")
        out.append("  - name value")
        out.append("")
        out.append("âœ… CORRECT: Dash + space, then key: value")
        out.append("items:")
        out.append("  - name: value")
        out.append("")
        out.append("âŒ WRONG: Row numbers in tabular")
        out.append("items[2,]{name,value}:")
        out.append("  0,Item1,100")
        out.append("  1,Item2,200")
        out.append("")
        out.append("âœ… CORRECT: No row numbers")
        out.append("items[2,]{name,value}:")
        out.append("  Item1,100")
        out.append("  Item2,200")
        out.append("")
        out.append("âŒ WRONG: Thousand separators")
        out.append("amount: 25,000")
        out.append("")
        out.append("âœ… CORRECT: Plain numbers")
        out.append("amount: 25000")
        out.append("")
        
        # ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸ ê°•í™”
        out.append("#### FINAL CHECKLIST BEFORE SUBMITTING:")
        out.append("âœ“ Every line has a colon (:)")
        out.append("âœ“ String fields = single value (NOT dash list)")
        if union_fields:
            out.append("âœ“ Union types = match document's actual type (NOT JSON string)")
        if special_char_fields:
            out.append("âœ“ Special characters = use quotes when needed")
        out.append("âœ“ Arrays = use [N]:item1,item2 or dash format (NOT JSON array string)")
        out.append("âœ“ Objects = nested key:value (NOT JSON object string)")
        out.append("âœ“ Indent with 2 spaces per level")
        out.append("âœ“ No thousand separators in numbers")
        out.append("âœ“ No row indices in tabular format")
        
        return "\n".join(out).strip()
    
    @staticmethod
    def _analyze_schema_structure(schema: Dict[str, Any]) -> Dict[str, Any]:
        """ìŠ¤í‚¤ë§ˆ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ê°€ì´ë“œ íƒ€ì…ì„ ê²°ì •í•©ë‹ˆë‹¤.
        
        Returns:
            dict: {
                'depth': int,  # ìµœëŒ€ ì¤‘ì²© ê¹Šì´
                'has_arrays': bool,
                'has_nested_objects': bool,
                'has_union_types': bool,
                'field_count': int,
                'array_fields': List[str],
                'nested_fields': List[str],
                'union_fields': List[str],
            }
        """
        props = schema.get("properties", {}) or {}
        required = set(schema.get("required", []))
        
        info = {
            'depth': 0,
            'has_arrays': False,
            'has_nested_objects': False,
            'has_union_types': False,
            'field_count': len(props),
            'array_fields': [],
            'nested_fields': [],
            'union_fields': [],
        }
        
        for fname, fsch in props.items():
            ftype = fsch.get("type")
            
            # Array ê°ì§€
            if ftype == "array":
                info['has_arrays'] = True
                info['array_fields'].append(fname)
            
            # Nested object ê°ì§€
            elif ftype == "object" or "properties" in fsch:
                info['has_nested_objects'] = True
                info['nested_fields'].append(fname)
                info['depth'] = max(info['depth'], 1)
            
            # Union íƒ€ì… ê°ì§€
            if "anyOf" in fsch or "oneOf" in fsch:
                info['has_union_types'] = True
                info['union_fields'].append(fname)
        
        return info
    
    @staticmethod
    def build_minimal_prompt(model: Type[BaseModel], cfg: ParserConfig = ParserConfig()) -> str:
        """ìŠ¤í‚¤ë§ˆ êµ¬ì¡°ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ìµœì í™”ëœ minimal instructions ìƒì„±.
        
        ì „ëµ:
        - Flat object (depth=0): ì´ˆê°„ê²° ê°€ì´ë“œ (~80 chars)
        - 1-depth nested: ì¤‘ê°„ ê°€ì´ë“œ (~150 chars)
        - 2-depth nested: ìƒì„¸ ê°€ì´ë“œ (~250 chars)
        
        ì†ìµë¶„ê¸°ì : ì¶œë ¥ì´ 1,121 chars ì´ìƒì¼ ë•Œ JSON ëŒ€ë¹„ íš¨ìœ¨ì 
        """
        schema = model.model_json_schema()
        required = schema.get("required", [])
        props = schema.get("properties", {}) or {}
        
        # ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ë¶„ì„
        struct_info = ToonIntelligence._analyze_schema_structure(schema)
        
        # ==========================================
        # CASE 1: Flat Object (depth=0, í•„ë“œ ë§ìŒ)
        # ==========================================
        if struct_info['depth'] == 0 and not struct_info['has_nested_objects']:
            example_lines = []
            
            # Required í•„ë“œ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ)
            for fname in list(required)[:5]:
                fsch = props.get(fname, {})
                ftype = fsch.get("type", "string")
                
                if ftype == "string":
                    example_lines.append(f"{fname}: text")
                elif ftype == "integer":
                    example_lines.append(f"{fname}: 123")
                elif ftype == "array":
                    example_lines.append(f"{fname}[2]: a,b")
                else:
                    example_lines.append(f"{fname}: value")
            
            # Optional í•„ë“œ ì˜ˆì‹œ 1ê°œ (ìƒëµ ê°€ëŠ¥í•¨ì„ ë³´ì—¬ì£¼ê¸°)
            optional_shown = 0
            for fname, fsch in props.items():
                if fname not in required and optional_shown < 1:
                    ftype = fsch.get("type", "string")
                    if ftype == "string":
                        example_lines.append(f"{fname}: optional")
                    else:
                        example_lines.append(f"{fname}: value")
                    optional_shown += 1
                    break
            
            example = "\n".join(example_lines)
            required_str = ", ".join(list(required)[:10]) if required else "none"
            
            return f"""TOON format (flat, NO indent):

{example}

key: value | key[N]: a,b,c
Required: {required_str}"""
        
        # ==========================================
        # CASE 2: Has Arrays or Union Types (but still flat)
        # ==========================================
        if struct_info['depth'] == 0 and (struct_info['has_arrays'] or struct_info['has_union_types']):
            example_lines = []
            
            # Required í•„ë“œ ì˜ˆì‹œ
            for fname in list(required)[:5]:
                fsch = props.get(fname, {})
                ftype = fsch.get("type", "string")
                
                if ftype == "string":
                    example_lines.append(f"{fname}: text")
                elif ftype == "integer":
                    example_lines.append(f"{fname}: 123")
                elif ftype == "array":
                    example_lines.append(f"{fname}[2]: item1,item2")
                else:
                    example_lines.append(f"{fname}: value")
            
            example = "\n".join(example_lines)
            required_str = ", ".join(list(required)[:10]) if required else "none"
            
            # Array ë˜ëŠ” Union ê°€ì´ë“œ ì¶”ê°€
            extra_guide = ""
            if struct_info['has_arrays']:
                extra_guide += "\nArrays: field[N]: val1,val2,val3"
            if struct_info['has_union_types']:
                extra_guide += "\nOptional fields: skip if not needed"
            
            return f"""TOON format (flat):

{example}

Rules: key: value{extra_guide}
Required: {required_str}"""
        
        # ==========================================
        # CASE 3: Has Nested Objects (1-2 depth)
        # ==========================================
        if struct_info['has_nested_objects'] or struct_info['depth'] > 0:
            example_lines = []
            
            # Required í•„ë“œ ì˜ˆì‹œ
            shown_nested = False
            for fname in list(required)[:4]:
                fsch = props.get(fname, {})
                ftype = fsch.get("type", "string")
                
                if ftype == "object" or "properties" in fsch and not shown_nested:
                    # Nested object ì˜ˆì‹œ 1ê°œ
                    example_lines.append(f"{fname}:")
                    nested_props = fsch.get("properties", {})
                    for nf in list(nested_props.keys())[:2]:
                        example_lines.append(f"  {nf}: value")
                    shown_nested = True
                elif ftype == "string":
                    example_lines.append(f"{fname}: text")
                elif ftype == "integer":
                    example_lines.append(f"{fname}: 123")
                elif ftype == "array":
                    example_lines.append(f"{fname}[2]: a,b")
                else:
                    example_lines.append(f"{fname}: value")
            
            example = "\n".join(example_lines)
            required_str = ", ".join(list(required)[:8]) if required else "none"
            
            return f"""TOON format:

{example}

Rules:
- key: value (inline)
- Nested: key: then indent 2 spaces
- Arrays: key[N]: a,b or dash list

Required: {required_str}"""
        
        # ==========================================
        # FALLBACK: Default minimal
        # ==========================================
        example_lines = []
        for fname in list(required)[:3]:
            fsch = props.get(fname, {})
            ftype = fsch.get("type", "string")
            
            if ftype == "string":
                example_lines.append(f"{fname}: text")
            elif ftype == "integer":
                example_lines.append(f"{fname}: 123")
            else:
                example_lines.append(f"{fname}: value")
        
        example = "\n".join(example_lines)
        required_str = ", ".join(required) if required else "none"
        
        return f"""TOON: key: value

{example}

Required: {required_str}"""


# ============================================================
# Core Parser
# ============================================================
class ToonParser:
    _TABULAR_HEADER_RE = re.compile(r"^(?P<name>[A-Za-z0-9_]+)\[(?P<n>\d+),(?:#)?\]\{(?P<cols>[^}]+)\}:\s*$")
    _SCALAR_LIST_RE = re.compile(r"^(?P<name>[A-Za-z0-9_]+)\[(?P<n>\d+)\]:\s*(?P<body>.*)$")
    _INDEXED_ITEM_RE = re.compile(r"^(?P<name>[A-Za-z0-9_]+)\[(?P<idx>\d+)\]:(?:\s*)$")
    _CODE_FENCE_RE = re.compile(r"```(?:toon)?\s*(.*?)\s*```", flags=re.DOTALL)

    def __init__(self, model: Type[BaseModel], cfg: ParserConfig = ParserConfig()):
        self.model = model
        self.cfg = cfg
        self.schema = model.model_json_schema()
        self.root_schema = self.schema
        self._defs: Dict[str, Any] = {}
        if isinstance(self.root_schema, dict):
            if isinstance(self.root_schema.get("$defs"), dict):
                self._defs.update(self.root_schema["$defs"])
            if isinstance(self.root_schema.get("definitions"), dict):
                self._defs.update(self.root_schema["definitions"])
        
        # minimal ëª¨ë“œì¼ ë•Œ ìŠ¤í‚¤ë§ˆ ë³µì¡ë„ ê²€ì¦ (ìë™ í´ë°± ì—¬ë¶€ì— ë”°ë¼ ë™ì‘)
        self._effective_mode = self.cfg.instructions_mode
        if self.cfg.instructions_mode == "minimal":
            self._validate_minimal_mode_compatibility()

    # ---------------- Validation ----------------
    def _validate_minimal_mode_compatibility(self):
        """minimal ëª¨ë“œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í‚¤ë§ˆì¸ì§€ ê²€ì¦.
        
        í•µì‹¬ ì œì•½: depth(ì¤‘ì²© ê¹Šì´)ë§Œ ê²€ì¦
        - max_nesting_depth=2: ê°ì²´ ì¤‘ì²© 2ë‹¨ê³„ê¹Œì§€ í—ˆìš©
        - ë‚˜ë¨¸ì§€ ì œì•½ (í•„ë“œ ê°œìˆ˜, íƒ€ì… ë“±)ì€ ì œí•œ ì—†ìŒ
        
        ë³µì¡í•œ ìŠ¤í‚¤ë§ˆì¼ ê²½ìš°:
        - auto_fallback_to_json=True: json ëª¨ë“œë¡œ ìë™ í´ë°± (ê²½ê³ ë§Œ ì¶œë ¥)
        - strict_minimal_validation=True: ModelComplexityError ë°œìƒ
        
        Raises:
            ModelComplexityError: strict_minimal_validation=Trueì´ê³  depthê°€ ì´ˆê³¼ëœ ê²½ìš°
        """
        # ë³µì¡ë„ ì œí•œ ì •ì˜ (minimal ëª¨ë“œ ê¸°ì¤€: depthë§Œ ì œí•œ)
        limits = ComplexityLimits(
            max_nesting_depth=2,  # ğŸ¯ í•µì‹¬: ìµœëŒ€ 2ë‹¨ê³„ ì¤‘ì²© (ì˜ˆ: user.job.companyê¹Œì§€ í—ˆìš©)
            max_array_nesting=999,  # ë°°ì—´ ì¤‘ì²© ë¬´ì œí•œ
            max_union_types=999,  # Union íƒ€ì… ë¬´ì œí•œ
            max_object_fields=999,  # flat ê°ì²´ í•„ë“œ ë¬´ì œí•œ
            max_array_item_fields=999,  # ë°°ì—´ ì•„ì´í…œ í•„ë“œ ë¬´ì œí•œ
            allow_nested_unions=True,  # ì¤‘ì²© Union í—ˆìš©
            allow_recursive_refs=False,  # ì¬ê·€ $refë§Œ ë¶ˆí—ˆ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
        )
        
        # ë³µì¡ë„ ë¶„ì„
        is_valid, metrics = ModelComplexityAnalyzer.validate_for_minimal_mode(
            self.model, limits
        )
        
        if not is_valid:
            model_name = self.model.__name__
            violation_summary = metrics.get_violation_summary()
            
            # strict ëª¨ë“œ: ì—ëŸ¬ ë°œìƒ
            if self.cfg.strict_minimal_validation:
                error_message = f"""
âŒ minimal ëª¨ë“œëŠ” depthê°€ ê¹Šì€ ìŠ¤í‚¤ë§ˆë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ëª¨ë¸: {model_name}
ì§€ì› ë¶ˆê°€ ì‚¬ìœ :
{violation_summary}

ğŸ“‹ minimal ëª¨ë“œ ì œì•½ ì‚¬í•­ (depthë§Œ ì œí•œ):
  - ìµœëŒ€ ì¤‘ì²© ê¹Šì´: {limits.max_nesting_depth}ë‹¨ê³„ (í˜„ì¬: {metrics.max_nesting_depth}ë‹¨ê³„) ğŸ¯
  - ë°°ì—´ ì¤‘ì²©: ë¬´ì œí•œ (í˜„ì¬: {metrics.max_array_nesting}ë‹¨ê³„)
  - Union íƒ€ì… í•„ë“œ: ë¬´ì œí•œ (í˜„ì¬: {metrics.union_type_count}ê°œ)
  - ê°ì²´ í•„ë“œ: ë¬´ì œí•œ (í˜„ì¬: {metrics.max_object_fields}ê°œ)
  - ë°°ì—´ ì•„ì´í…œ í•„ë“œ: ë¬´ì œí•œ (í˜„ì¬: {metrics.max_array_item_fields}ê°œ)

ğŸ’¡ í•´ê²° ë°©ë²•:
  1. ìë™ í´ë°± í—ˆìš© (ê¶Œì¥)
     cfg = ParserConfig(instructions_mode="minimal", auto_fallback_to_json=True)
  
  2. instructions_mode="json"ìœ¼ë¡œ ë³€ê²½ (í‘œì¤€ JSON ì‚¬ìš©)
     cfg = ParserConfig(instructions_mode="json")
  
  3. ìŠ¤í‚¤ë§ˆ ì¤‘ì²©ì„ 2ë‹¨ê³„ ì´í•˜ë¡œ ì¤„ì´ê¸° (í•„ë“œ ê°œìˆ˜ëŠ” ìƒê´€ ì—†ìŒ)
""".strip()
                
                raise ModelComplexityError(error_message)
            
            # ìë™ í´ë°± ëª¨ë“œ: jsonìœ¼ë¡œ ì „í™˜í•˜ê³  ê²½ê³  ì¶œë ¥
            if self.cfg.auto_fallback_to_json:
                self._effective_mode = "json"
                
                import warnings
                warning_message = f"""
âš ï¸ minimal ëª¨ë“œëŠ” '{model_name}' ìŠ¤í‚¤ë§ˆì˜ depthê°€ ë„ˆë¬´ ê¹Šì–´ ìë™ìœ¼ë¡œ JSON ëª¨ë“œë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.

ì§€ì› ë¶ˆê°€ ì‚¬ìœ :
{violation_summary}

ğŸ“‹ minimal ëª¨ë“œ ì œì•½ ì‚¬í•­ (depthë§Œ ì œí•œ):
  - ìµœëŒ€ ì¤‘ì²© ê¹Šì´: {limits.max_nesting_depth}ë‹¨ê³„ (í˜„ì¬: {metrics.max_nesting_depth}ë‹¨ê³„) ğŸ¯
  - ë°°ì—´ ì¤‘ì²©: ë¬´ì œí•œ (í˜„ì¬: {metrics.max_array_nesting}ë‹¨ê³„)
  - Union íƒ€ì… í•„ë“œ: ë¬´ì œí•œ (í˜„ì¬: {metrics.union_type_count}ê°œ)
  - ê°ì²´ í•„ë“œ: ë¬´ì œí•œ (í˜„ì¬: {metrics.max_object_fields}ê°œ)
  - ë°°ì—´ ì•„ì´í…œ í•„ë“œ: ë¬´ì œí•œ (í˜„ì¬: {metrics.max_array_item_fields}ê°œ)

ğŸ’¡ JSON ëª¨ë“œëŠ” í‘œì¤€ JSON í˜•ì‹ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ëª¨ë“  ë³µì¡ë„ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
   TOONì˜ ì••ì¶• íš¨ê³¼ëŠ” ì—†ì§€ë§Œ, íŒŒì‹± ì„±ê³µë¥ ì´ ë†’ìŠµë‹ˆë‹¤.

ì´ ê²½ê³ ë¥¼ ë„ë ¤ë©´:
  cfg = ParserConfig(instructions_mode="json")  # ì²˜ìŒë¶€í„° JSON ëª¨ë“œ ì‚¬ìš©
""".strip()
                
                warnings.warn(warning_message, UserWarning, stacklevel=3)
    
    # ---------------- Public ----------------
    def get_format_instructions(self) -> str:
        """Format instructions ë°˜í™˜ (ì„¤ì •ì— ë”°ë¼ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©)
        
        Note: minimal ëª¨ë“œì—ì„œ ìë™ í´ë°±ëœ ê²½ìš° _effective_modeê°€ "json"ìœ¼ë¡œ ë³€ê²½ë¨
        """
        # ìë™ í´ë°±ì´ ë°œìƒí–ˆì„ ê²½ìš° effective_mode ì‚¬ìš©
        effective_mode = getattr(self, '_effective_mode', self.cfg.instructions_mode)
        
        if effective_mode == "minimal":
            # Few-shot ìŠ¤íƒ€ì¼ (85% ê°ì¶•, ì†ìµë¶„ê¸° 1,121 chars)
            return ToonIntelligence.build_minimal_prompt(self.model, self.cfg)
        elif effective_mode == "json":
            # JSON í¬ë§· ì‚¬ìš© (TOON ë¹„í™œì„±í™”)
            return self._get_json_schema_instructions()
        else:  # "adaptive" (ê¸°ë³¸ê°’)
            # ìƒì„¸í•œ ì„¤ëª… (êµìœ¡ìš©, ë””ë²„ê¹…ìš©)
            return ToonIntelligence.build_adaptive_prompt(self.model, self.cfg)
    
    def _get_json_schema_instructions(self) -> str:
        """JSON í¬ë§· instructions (ë¹„êµìš©)"""
        import json
        schema_str = json.dumps(self.model.model_json_schema(), ensure_ascii=False, indent=2)
        return f"""You must output ONLY a valid JSON object. Your response must start with {{ and end with }}.

Schema:
{schema_str}

CRITICAL RULES:
- DO NOT use ```json, ```toon, or ``` code fences
- DO NOT add any explanations before or after the JSON
- DO NOT add any markdown formatting
- Start directly with {{ and end with }}
- Output pure JSON only"""

    # ------------- Schema helpers (Pydantic $ref / Optional) -------------
    def _resolve_ref(self, ref: str) -> Dict[str, Any]:
        # Supported refs: #/$defs/Name or #/definitions/Name
        if not ref.startswith("#/"):
            raise ToonDecodeError(f"Unsupported $ref: {ref}")
        parts = ref.lstrip("#/").split("/")
        if len(parts) == 2 and parts[0] in ("$defs", "definitions"):
            name = parts[1]
            target = self._defs.get(name)
            if not isinstance(target, dict):
                raise ToonDecodeError(f"$ref not found: {ref}")
            return target
        raise ToonDecodeError(f"Unsupported $ref path: {ref}")

    def _resolve_schema(self, schema: Any) -> Any:
        # Resolve direct $ref chains. Merge sibling constraints with resolved schema.
        cur = schema
        seen = set()
        while isinstance(cur, dict) and "$ref" in cur:
            ref = cur.get("$ref")
            if not isinstance(ref, str):
                break
            if ref in seen:
                raise ToonDecodeError(f"Cyclic $ref detected: {ref}")
            seen.add(ref)
            base = {k: v for k, v in cur.items() if k != "$ref"}
            resolved = dict(self._resolve_ref(ref))
            if base:
                resolved.update(base)
            cur = resolved
        return cur

    def _unwrap_nullable(self, schema: Any) -> Any:
        schema = self._resolve_schema(schema)
        if isinstance(schema, dict):
            for key in ("anyOf", "oneOf"):
                if key in schema and isinstance(schema[key], list):
                    non_null = [
                        s for s in schema[key]
                        if not (isinstance(s, dict) and s.get("type") == "null")
                    ]
                    if len(non_null) == 1:
                        return self._resolve_schema(non_null[0])
        return schema

    def _resolve_nullable(self, schema: Any) -> Any:
        return self._unwrap_nullable(schema)

    def decode(self, text: str) -> Dict[str, Any]:
        """TOON í…ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë””ì½”ë”© (Pydantic ê²€ì¦ ì—†ì´).
        
        Args:
            text: TOON í˜•ì‹ì˜ í…ìŠ¤íŠ¸
            
        Returns:
            Dict[str, Any]: ë””ì½”ë”©ëœ ë”•ì…”ë„ˆë¦¬ (Pydantic ê²€ì¦ ì „)
        """
        # JSON ëª¨ë“œì¸ ê²½ìš° (ë˜ëŠ” ìë™ í´ë°±ëœ ê²½ìš°) JSONìœ¼ë¡œ íŒŒì‹±
        effective_mode = getattr(self, '_effective_mode', self.cfg.instructions_mode)
        if effective_mode == "json":
            import json
            try:
                # JSON ì¶”ì¶œ ì‹œë„ (ì½”ë“œíœìŠ¤ ì œê±°)
                s = (text or "").strip()
                # ```json ... ```, ```toon ... ```, ``` ... ``` ëª¨ë‘ ì œê±°
                if s.startswith("```") and s.endswith("```"):
                    lines = s.split("\n")
                    # ì²« ì¤„ì´ ```json, ```toon, ``` ë“±ì¸ ê²½ìš° ì œê±°
                    s = "\n".join(lines[1:-1])
                return json.loads(s)
            except json.JSONDecodeError as e:
                raise ToonDecodeError(f"JSON parsing failed: {e}")
        
        # TOON ëª¨ë“œ íŒŒì‹±
        lines = self._normalize_lines(text)
        if not lines:
            raise ToonParserError("Empty input. Model produced no parsable TOON.")
        obj, next_i = self._parse_object(lines, 0, 0, self.schema, path="$")
        
        # remain check
        if next_i < len(lines):
            rest = [ln for ln in lines[next_i:] if ln.strip()]
            if rest:
                raise ToonParserError(f"Unparsed tail remains at line {next_i+1}: {rest[0]!r}")
        
        return obj

    def parse(self, text: str) -> BaseModel:
        # JSON ëª¨ë“œì¸ ê²½ìš° (ë˜ëŠ” ìë™ í´ë°±ëœ ê²½ìš°) JSONìœ¼ë¡œ íŒŒì‹±
        effective_mode = getattr(self, '_effective_mode', self.cfg.instructions_mode)
        if effective_mode == "json":
            import json
            try:
                # JSON ì¶”ì¶œ ì‹œë„ (ì½”ë“œíœìŠ¤ ì œê±°)
                s = (text or "").strip()
                # ```json ... ```, ```toon ... ```, ``` ... ``` ëª¨ë‘ ì œê±°
                if s.startswith("```") and s.endswith("```"):
                    lines = s.split("\n")
                    # ì²« ì¤„ì´ ```json, ```toon, ``` ë“±ì¸ ê²½ìš° ì œê±°
                    s = "\n".join(lines[1:-1])
                obj = json.loads(s)
                return self.model.model_validate(obj)
            except json.JSONDecodeError as e:
                raise ToonDecodeError(f"JSON parsing failed: {e}")
        
        # TOON ëª¨ë“œ íŒŒì‹±
        lines = self._normalize_lines(text)
        if not lines:
            raise ToonParserError("Empty input. Model produced no parsable TOON.")
        obj, next_i = self._parse_object(lines, 0, 0, self.schema, path="$")

        # remain check
        if next_i < len(lines):
            rest = [ln for ln in lines[next_i:] if ln.strip()]
            if rest:
                raise ToonParserError(f"Unparsed tail remains at line {next_i+1}: {rest[0]!r}")

        return self.model.model_validate(obj)

    # ---------------- Normalization ----------------
    def _normalize_lines(self, text: str) -> List[str]:
        s = (text or "").strip()
        m = self._CODE_FENCE_RE.search(s)
        if m:
            s = m.group(1).strip()
        raw = s.splitlines()
        lines = [ln.rstrip() for ln in raw]
        lines = [ln for ln in lines if ln.strip()]
        return lines

    # ---------------- Helpers ----------------
    def _count_indent(self, line: str) -> int:
        if "\t" in line[: line.find(line.lstrip(" ")) if line.lstrip(" ") else 0]:
            raise ToonParserError("Tabs are not allowed. Use spaces only.")
        return len(line) - len(line.lstrip(" "))

    def _split_kv(self, stripped: str) -> Tuple[str, Optional[str]]:
        # split on first ":"
        if ":" not in stripped:
            # Be more tolerant: return None to indicate skip this line
            # This allows the parser to be more robust with malformed LLM output
            return "", None
        k, v = stripped.split(":", 1)
        k = k.strip()
        v = v.strip()
        if v == "":
            return k, None
        return k, v

    def _parse_scalar(self, raw: str, expected_schema: Optional[Dict[str, Any]] = None) -> Any:
        v = raw.strip()
        if v == "null":
            return None
        if v == "{}":
            return {}
        if v == "[]":
            return []
        # quoted
        if (len(v) >= 2) and ((v[0] == v[-1] == '"') or (v[0] == v[-1] == "'")):
            v = v[1:-1]

        expected_type = (expected_schema or {}).get("type")

        # preserve string if schema says string
        if expected_type == "string" and self.cfg.protect_string_ids:
            return v

        # boolean
        if v.lower() in ("true", "false"):
            return v.lower() == "true"

        # int / float
        # NOTE: no thousand separators supported
        if re.fullmatch(r"-?\d+", v):
            if expected_type == "number":
                return float(v)
            if expected_type == "integer":
                return int(v)
            if expected_type == "string":
                return v
            # heuristic: prefer int
            return int(v)

        if re.fullmatch(r"-?\d+\.\d+", v):
            if expected_type == "integer":
                # force int parse would fail; keep float
                return float(v)
            return float(v)

        return v

    def _csv_row(self, row_line: str) -> List[str]:
        # allow spaces; treat as CSV single line
        buf = io.StringIO(row_line)
        reader = csv.reader(buf, skipinitialspace=True)
        return next(reader, [])

    # ---------------- Schema helpers ----------------
    def _get_props(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        return schema.get("properties", {}) or {}

    def _schema_allows_additional(self, schema: Dict[str, Any]) -> bool:
        # dict[str, Any] or free-form object
        if schema.get("type") != "object":
            return False
        ap = schema.get("additionalProperties", None)
        if ap is True:
            return True
        # If additionalProperties is an object/schema (not just boolean), it's flexible
        if isinstance(ap, dict):
            return True
        # if no properties defined, treat as flexible
        if not (schema.get("properties") or {}):
            if ap is None:
                return True
        return False

    # ---------------- Parsers ----------------
    def _parse_object(
        self, lines: List[str], i: int, indent: int, schema: Dict[str, Any], path: str
    ) -> Tuple[Dict[str, Any], int]:
        out: Dict[str, Any] = {}
        props = self._get_props(schema)
        allow_additional = self._schema_allows_additional(schema)

        indexed_buffers: Dict[str, Dict[int, Dict[str, Any]]] = {}

        while i < len(lines):
            line = lines[i]
            cur_indent = self._count_indent(line)
            if cur_indent < indent:
                break
            if cur_indent > indent:
                raise ToonParserError(f"Unexpected indent at {path} (line {i+1})")

            stripped = line.strip()

            # Tabular header
            tm = self._TABULAR_HEADER_RE.match(stripped)
            if tm:
                fname = tm.group("name")
                fsch = props.get(fname)
                if fsch is None and not allow_additional and self.cfg.strict_schema:
                    raise SchemaViolationError(f"Unknown field '{fname}' at {path}")
                val, i = self._parse_tabular(lines, i, indent, fname, fsch, path=f"{path}.{fname}")
                out[fname] = val
                continue

            # Scalar list
            sm = self._SCALAR_LIST_RE.match(stripped)
            if sm:
                fname = sm.group("name")
                n = int(sm.group("n"))
                body = sm.group("body")
                fsch = props.get(fname)
                if fsch is None and not allow_additional and self.cfg.strict_schema:
                    raise SchemaViolationError(f"Unknown field '{fname}' at {path}")
                items_schema = (fsch or {}).get("items", {}) if (fsch or {}).get("type") == "array" else None
                parts = [p.strip() for p in body.split(",")] if body else []
                parts = [p for p in parts if p != ""]
                if self.cfg.strict_count and len(parts) != n:
                    raise SchemaViolationError(f"{path}.{fname}: expected {n} items, got {len(parts)}")
                out[fname] = [self._parse_scalar(p, items_schema) for p in parts]
                i += 1
                continue

            # Indexed array item
            im = self._INDEXED_ITEM_RE.match(stripped)
            if im:
                fname = im.group("name")
                idx = int(im.group("idx"))
                fsch = props.get(fname)
                if fsch is None and not allow_additional and self.cfg.strict_schema:
                    raise SchemaViolationError(f"Unknown field '{fname}' at {path}")
                if (fsch or {}).get("type") != "array":
                    raise SchemaViolationError(f"{path}.{fname}[{idx}]: indexed notation used for non-array field")
                items_schema = (fsch or {}).get("items", {}) or {}
                # parse nested object block
                i += 1
                obj, i = self._parse_object(lines, i, indent + self.cfg.indent_step, items_schema, path=f"{path}.{fname}[{idx}]")
                indexed_buffers.setdefault(fname, {})[idx] = obj
                continue

            # key/value or block
            key, val = self._split_kv(stripped)
            
            # Skip invalid lines (no colon found)
            if key == "" and val is None:
                i += 1
                continue
            
            fsch = self._resolve_nullable(props.get(key))

            if fsch is None and not allow_additional and self.cfg.strict_schema:
                raise SchemaViolationError(f"Unknown field '{key}' at {path}")

            if val is not None:
                out[key] = self._parse_scalar(val, fsch)
                i += 1
                continue

            # block
            i += 1
            # empty block -> treat as {} or []
            if i >= len(lines) or self._count_indent(lines[i]) <= indent:
                if (fsch or {}).get("type") == "array":
                    out[key] = []
                else:
                    out[key] = {}
                continue

            # Check if next line starts with dash (array) regardless of schema
            next_line_is_dash = False
            if i < len(lines):
                next_stripped = lines[i].strip()
                next_line_is_dash = next_stripped.startswith("-")
            
            # decide array/object
            if (fsch or {}).get("type") == "array" or next_line_is_dash:
                # Parse as array if schema says array OR if content starts with dash
                arr, i = self._parse_array_block(lines, i, indent + self.cfg.indent_step, fsch or {"type": "array", "items": {}}, path=f"{path}.{key}")
                out[key] = arr
            elif (fsch or {}).get("type") == "object" or self._schema_allows_additional(fsch or {}) or not fsch:
                # Parse as object if schema says object, allows additional properties, or schema is undefined
                obj, i = self._parse_object(lines, i, indent + self.cfg.indent_step, fsch or {}, path=f"{path}.{key}")
                out[key] = obj
            else:
                # Scalar field with block content - be more tolerant
                # Try to parse as object anyway (LLM might have output wrong format)
                # If schema is not defined or ambiguous, treat as flexible object
                try:
                    obj, i = self._parse_object(lines, i, indent + self.cfg.indent_step, {}, path=f"{path}.{key}")
                    out[key] = obj
                except Exception:
                    # If parsing as object fails, skip the block and set to empty dict
                    while i < len(lines) and self._count_indent(lines[i]) > indent:
                        i += 1
                    out[key] = {}

        # finalize indexed buffers
        for fname, buf in indexed_buffers.items():
            if fname in out:
                raise ToonParserError(f"{path}.{fname}: both indexed notation and other notation used")
            max_idx = max(buf.keys()) if buf else -1
            lst: List[Any] = [None] * (max_idx + 1)
            for idx, obj in buf.items():
                lst[idx] = obj
            # compact: drop None tail? keep for schema? keep as-is; pydantic will raise if None not allowed
            out[fname] = lst

        return out, i

    def _parse_array_block(
        self, lines: List[str], i: int, indent: int, field_schema: Dict[str, Any], path: str
    ) -> Tuple[List[Any], int]:
        # Only dash lists are accepted in block arrays
        out: List[Any] = []
        items_schema = field_schema.get("items", {}) or {}

        while i < len(lines):
            line = lines[i]
            cur_indent = self._count_indent(line)
            if cur_indent < indent:
                break
            if cur_indent > indent:
                raise ToonParserError(f"Unexpected indent inside array at {path} (line {i+1})")

            stripped = line.strip()
            if not stripped.startswith("- "):
                # Also accept just "-" without space for robustness
                if not stripped.startswith("-"):
                    break
                else:
                    # Handle "- key: value" or "-key: value" (missing space after dash)
                    item_text = stripped[1:].strip()
            else:
                item_text = stripped[2:].strip()

            # object item " - key: value" or " - key:"
            if ":" in item_text:
                k, v = item_text.split(":", 1)
                k = k.strip()
                v = v.strip()
                obj: Dict[str, Any] = {}
                props = self._get_props(items_schema) if items_schema.get("type") in (None, "object") else {}

                # first key
                if v == "":
                    # nested block for this key
                    i += 1
                    nested, i = self._parse_value_block(lines, i, indent + self.cfg.indent_step, props.get(k), path=f"{path}[-].{k}")
                    obj[k] = nested
                else:
                    obj[k] = self._parse_scalar(v, props.get(k))

                i += 1
                # consume additional fields for this object at indent+step
                while i < len(lines):
                    ln = lines[i]
                    ind = self._count_indent(ln)
                    if ind < indent + self.cfg.indent_step:
                        break
                    # Don't break on deeper indents - they might be nested arrays/objects
                    if ind == indent + self.cfg.indent_step:
                        # Same level field
                        stripped_ln = ln.strip()
                        # Skip if it's a dash (part of nested array)
                        if stripped_ln.startswith("-"):
                            break
                        sk, sv = self._split_kv(stripped_ln)
                        # Skip invalid lines
                        if sk == "" and sv is None:
                            i += 1
                            continue
                        psch = props.get(sk)
                        if sv is None:
                            i += 1
                            # Resolve schema before passing to _parse_value_block
                            resolved_psch = self._resolve_nullable(psch) if psch else None
                            nested, i = self._parse_value_block(lines, i, indent + 2 * self.cfg.indent_step, resolved_psch, path=f"{path}[-].{sk}")
                            obj[sk] = nested
                        else:
                            obj[sk] = self._parse_scalar(sv, psch)
                            i += 1
                    else:
                        # Deeper indent - it's part of a nested structure, let recursion handle it
                        break

                out.append(obj)
                continue

            # scalar item "- value"
            out.append(self._parse_scalar(item_text, items_schema))
            i += 1

        return out, i

    def _parse_value_block(
        self, lines: List[str], i: int, indent: int, schema: Optional[Dict[str, Any]], path: str
    ) -> Tuple[Any, int]:
        schema = schema or {}
        # decide by next line: dash list or object
        if i >= len(lines):
            return {}, i
        next_indent = self._count_indent(lines[i])
        if next_indent < indent:
            return {}, i

        # Check actual content: if next line starts with dash, it's an array
        next_line_stripped = lines[i].strip()
        content_is_array = next_line_stripped.startswith("-")
        
        # Prefer content-based detection over schema
        if content_is_array:
            # Content shows it's an array, parse as array
            return self._parse_array_block(lines, i, indent, schema or {"type": "array", "items": {}}, path)
        
        if schema.get("type") == "array":
            return self._parse_array_block(lines, i, indent, schema, path)
        if schema.get("type") == "object" or self._schema_allows_additional(schema):
            return self._parse_object(lines, i, indent, schema, path)
        # fallback: treat as object
        return self._parse_object(lines, i, indent, schema, path)

    def _parse_tabular(
        self, lines: List[str], i: int, indent: int, fname: str, field_schema: Optional[Dict[str, Any]], path: str
    ) -> Tuple[List[Dict[str, Any]], int]:
        # header line already matched
        header = lines[i].strip()
        m = self._TABULAR_HEADER_RE.match(header)
        assert m
        n = int(m.group("n"))
        cols = [c.strip() for c in m.group("cols").split(",") if c.strip()]

        fsch = field_schema or {}
        if fsch.get("type") != "array":
            raise SchemaViolationError(f"{path}: tabular used for non-array field")

        # policy: forbid tabular for complex arrays
        if ToonIntelligence.is_complex_array(fsch, self.cfg.complexity_threshold):
            raise PolicyViolationError(
                f"{path}: tabular(items[N,]{{cols}}) is FORBIDDEN for complex arrays. Use Dash(-) notation."
            )

        items_schema = self._resolve_nullable(fsch.get("items", {}) or {})
        item_props = items_schema.get("properties", {}) or {}

        if self.cfg.strict_schema and item_props:
            unknown_cols = [c for c in cols if c not in item_props]
            if unknown_cols:
                raise SchemaViolationError(f"{path}: unknown tabular columns: {unknown_cols}")

        out: List[Dict[str, Any]] = []
        i += 1
        row_idx = 0
        while i < len(lines):
            line = lines[i]
            cur_indent = self._count_indent(line)
            if cur_indent <= indent:
                break
            if cur_indent != indent + self.cfg.indent_step:
                # tolerate deeper indent by trimming left, but keep simple rule
                if cur_indent < indent + self.cfg.indent_step:
                    break

            row = self._csv_row(line.strip())

            # Row Index Defense
            if len(row) == len(cols) + 1:
                c0 = (row[0] or "").strip()
                if c0.isdigit():
                    v = int(c0)
                    if v == row_idx or v == row_idx + 1:
                        row = row[1:]

            if self.cfg.strict_count and row_idx >= n:
                break

            # ensure length
            if len(row) < len(cols):
                # pad None
                row = row + ["null"] * (len(cols) - len(row))
            if len(row) > len(cols):
                # keep extra as error (unless it's benign whitespace)
                raise SchemaViolationError(f"{path}: too many columns in row {row_idx}: got {len(row)}, expected {len(cols)}")

            d: Dict[str, Any] = {}
            for j, c in enumerate(cols):
                expected = item_props.get(c) if item_props else None
                d[c] = self._parse_scalar(row[j], expected)
            out.append(d)

            row_idx += 1
            i += 1
            if self.cfg.strict_count and row_idx >= n:
                break

        # if strict_count, enforce n
        if self.cfg.strict_count and row_idx != n:
            raise SchemaViolationError(f"{path}: expected {n} rows, got {row_idx}")

        return out, i
